简陋的训练流程，是用四张图片的数据集，训练2次无法得到结果，20次可以得到较模糊的结果
简陋的训练流程，使用30张图，训练20次就可以得到有参差的结果，训练20次就越界很准确了
简陋的训练流程，使用558张图，训练2次就有结果，但是好像是过拟合的现象，因为分割结果全是镂空的
这两次实验都是看起来，并没有统计iou


cv2全是BGR，都要换成RGB

如果训练时BGR，测试时RGB会导致严重降低正确率

由于使用cv2的原因
要保证训练时与测试时input的图片通道相同，即RGB或BGR


使用超小数据集（4），训练12次没有结果，88次有模糊的效果，333次比88次稍微好点

回顾细胞备份：
回顾细胞备份发现一个结论，因为在细胞备份没有开数据增强的norm，而测试时忘记关闭norm，导致结果特别不明显。猜测原因是因为norm会把所有值映射到01区间，然而训练时没有映射到01区间，像素的值比较大，训练也是按照大像素值训练的，如果这种情况下在测试时使用norm，就相当于测试用数据被norm到01之间，测试值就很小了，神经网络因为用大值训练，对小值的敏感程度低，所以效果不好。这也反映了像素值的大小区间，对神经网络的训练测试，输入输出都是有影响的。
回顾细胞备份发现另一个结论：batchsize影响效果很大，并且影响训练速度，batchsize=1不仅效果差训练还慢，batchsize=8效果好速度快。这说明，batchsize大的话，在python作用域的for循环执行次数少，可以明显提速
在寻找区别时尝试不同优化器对训练的影响：然而优化器并不是确定训练效果好坏的重要因素。反而Adam优化器能让输出的像素值的区分度能大。（指的是在取值区间内的分布梯度更加陡峭，而不是平缓模糊的）
再测试训练速度时发现加入iou指标会稍微拖慢训练速度

#给细胞任务的mask换成01后，效果非常差，几乎没效果了，所以mask的值还是要与img匹配。不过尚未测试使用01mask同时给img做norm是什么效果
#已测试01mask的同时仅仅对img做norm：测试时必须使用小范围测试，发现效果还行，但远不如0255正常训练。感觉是把正常训练的输出结果值的区间也缩小了。